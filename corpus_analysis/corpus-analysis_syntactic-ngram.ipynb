{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e9b99857",
      "metadata": {},
      "source": [
        "# üöÄ Analyse syntaktischer N-Gramme  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b561cbd",
      "metadata": {},
      "source": [
        "## Hinweise zur Ausf√ºhrung des Notebooks\n",
        "Dieses **Notebook** kann auf unterschiedlichen Levels erarbeitet werden (siehe Abschnitt [\"Technische Voraussetzungen\"](../introduction/introduction_requirements)): \n",
        "1. Book-Only Mode\n",
        "2. Cloud Mode: Daf√ºr auf üöÄ klicken und z.B. in Colab ausf√ºhren.\n",
        "3. Local Mode: Daf√ºr auf Herunterladen ‚Üì klicken und \".ipynb\" w√§hlen. \n",
        "\n",
        "## √úbersicht \n",
        "Im Folgenden wird das Korpus mithilfe **syntaktischer n-Gramme** analysiert. Ziel dieser Analyse ist es, wiederkehrende **grammatische Muster** (insbesondere adjektivische Modifikationen von Substantiven) √ºber Zeit zu untersuchen und damit √ºber rein lexikalische H√§ufigkeiten hinauszugehen. Im Unterschied zur Analyse semantischer Felder stehen hier **strukturierte, syntaktisch motivierte Wortkombinationen** im Fokus, die auf Abh√§ngigkeitsbeziehungen basieren.\n",
        "\n",
        "Konkret wird untersucht, wie h√§ufig bestimmte syntaktische Konstruktionen (z. B. *Adjektiv ‚Üí Substantiv*-Relationen) im Korpus auftreten und wie sich deren Vorkommen zeitlich entwickelt. Dies erlaubt es, stilistische und diskursive Entwicklungen sichtbar zu machen, etwa Ver√§nderungen in der Beschreibung bestimmter Konzepte √ºber l√§ngere Zeitr√§ume hinweg.\n",
        "\n",
        "Dazu werden die folgenden Schritte durchgef√ºhrt:\n",
        "\n",
        "1. Einlesen des Korpus, der Metadaten sowie der bereits erzeugten spaCy-Annotationen\n",
        "2. Auswahl relevanter Dependency-Relationen zur Bildung syntaktischer n-Gramme\n",
        "3. Extraktion syntaktischer n-Gramme auf Basis der vorhandenen Abh√§ngigkeitsinformationen\n",
        "4. Aggregation der syntaktischen Muster nach Zeit (z. B. Jahre oder Zeitintervalle)\n",
        "5. Analyse und Visualisierung der zeitlichen Entwicklung ausgew√§hlter syntaktischer n-Gramme\n",
        "6. Diskussion der Ergebnisse im Hinblick auf stilistische und diskursive Ver√§nderungen im Korpus"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0874bcf",
      "metadata": {},
      "source": [
        "## Import der Bibliotheken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67c16814",
      "metadata": {
        "tags": [
          "hide-cell"
        ]
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from typing import Dict, List, Union, Tuple\n",
        "from collections import OrderedDict, Counter\n",
        "from time import time\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = \"notebook\"\n",
        "import plotly.graph_objects as go\n",
        "from itables import show\n",
        "from tqdm import tqdm\n",
        "import spacy\n",
        "from spacy.tokens import DocBin, Doc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a476052",
      "metadata": {},
      "source": [
        "Laden des spaCy-Modells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4064c8db",
      "metadata": {
        "tags": [
          "hide-cell"
        ]
      },
      "outputs": [],
      "source": [
        "! python -m spacy download de_core_news_sm\n",
        "nlp = spacy.load(\"de_core_news_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9970c60e",
      "metadata": {},
      "source": [
        "## Laden der Annotationen\n",
        "\n",
        "In diesem Schritt werden die zuvor erzeugten spaCy-Annotationen aus dem Dateisystem eingelesen. Die gespeicherten DocBin-Dateien werden zu vollst√§ndigen spaCy.Doc-Objekten rekonstruiert und in einer Datenstruktur abgelegt, die eine weitere Analyse erlaubt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "955f6b97",
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "# Bei Verwendung eines anderen Korpus hier den Verzeichnisnamen anpassen\n",
        "annotation_dir = Path(\"../data/spacy\")\n",
        "\n",
        "if not annotation_dir.exists():\n",
        "    print(\"The directory does not exist, please check the path again.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c98b489",
      "metadata": {
        "tags": [
          "skip-execution",
          "hide-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# Create dictionary to save the corpus data (filenames and tables)\n",
        "annotated_docs = {}\n",
        "\n",
        "start = time()\n",
        "# Iterate over spacy files\n",
        "for fp in tqdm(annotation_dir.iterdir(), desc=\"Reading annotated data\"):\n",
        "    # check if the entry is a file, not a directory\n",
        "    if fp.is_file():\n",
        "        # check if the file has the correct suffix spacy\n",
        "        if fp.suffix == '.spacy':\n",
        "            print( f\"Loading file: {fp.name}\" )\n",
        "            # load spacy DocBin objects\n",
        "            doc_bin = DocBin().from_disk(fp)\n",
        "            chunk_docs = list(doc_bin.get_docs(nlp.vocab))\n",
        "            # merge bins into one single document\n",
        "            full_doc = Doc.from_docs(chunk_docs)\n",
        "\n",
        "            # save the data frame to the dictionary, key=filename (without suffix), value=spacy.Doc\n",
        "            annotated_docs[fp.stem] = full_doc\n",
        "took = time() - start\n",
        "print(f\"Loading the data took: {round(took, 4)} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c8fc9dc",
      "metadata": {
        "tags": [
          "skip-execution",
          "hide-cell"
        ]
      },
      "outputs": [],
      "source": [
        "print(f\"Annotations of first 20 lines of the text: {list(annotated_docs.keys())[0]}:\\n\")\n",
        "print(\"Token\\tLemma\\tPoS\")\n",
        "for token in annotated_docs[list(annotated_docs.keys())[0]][:20]:\n",
        "    print(f\"{token.text}\\t{token.lemma_}\\t{token.pos_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb4a9945",
      "metadata": {},
      "source": [
        "## Metadaten einlesen\n",
        "\n",
        "Anschlie√üend werden die zugeh√∂rigen Metadaten geladen und auf diejenigen Texte beschr√§nkt, f√ºr die Annotationen vorliegen. Die zeitlichen Angaben werden in ein geeignetes Datumsformat √ºberf√ºhrt, um sp√§tere zeitbasierte Aggregationen und Visualisierungen zu erleichtern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9071e6e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "metadata_df = pd.read_csv(\"../metadata/metadata_corpus-german_language_fiction_1820-1900_50-per-decade.csv\")\n",
        "# metadata_df = metadata_df[metadata_df['ID'].isin(annotated_docs.keys())]\n",
        "# Datentyp der Datumsspalte f√ºr eine einfachere Weiterverarbeitung √§ndern\n",
        "metadata_df['year'] = pd.to_datetime(metadata_df['year'], format=\"%Y\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0811463d",
      "metadata": {},
      "outputs": [],
      "source": [
        "show(metadata_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44ce3bf3",
      "metadata": {},
      "outputs": [],
      "source": [
        "metadata_df_alt = pd.read_csv(\"../metadata/metadata_corpus-german_language_fiction_1820-1900_50-per-decade_ALT.csv\")\n",
        "# metadata_df_alt = metadata_df_alt[metadata_df_alt['ID'].isin(annotated_docs.keys())]\n",
        "# Datentyp der Datumsspalte f√ºr eine einfachere Weiterverarbeitung √§ndern\n",
        "metadata_df_alt['year'] = pd.to_datetime(metadata_df_alt['year'], format=\"%Y\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f33aee8",
      "metadata": {},
      "outputs": [],
      "source": [
        "show(metadata_df_alt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9653ad17",
      "metadata": {},
      "source": [
        "## Syntaktische N-Gramme extrahieren"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15873ce4",
      "metadata": {},
      "source": [
        "In einem weiteren Schritt k√∂nnen wir die Adjektive extrahieren, die mit dem Nomen Luft in Verbindung stehen. Wir machen dabei Gebrauch von den Dependenzstrukturen, die sich durch das spaCy-eigene `Doc` einfach navigieren lassen. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d536a3f5",
      "metadata": {
        "tags": [
          "hide-cell"
        ]
      },
      "outputs": [],
      "source": [
        "def extract_dependent_adjective_list(spacy_docs: Dict, metadata_df: pd.DataFrame,\n",
        "                                     noun_input: Union[str, List[str]], top_n: int = 10) -> Tuple[pd.DataFrame, List[str]]:\n",
        "    \"\"\"\n",
        "    Extract adjective modifiers (amod) for a noun or list of nouns and track their frequency over time.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    spacy_docs : dict\n",
        "        Dictionary with file_ids as keys and spaCy Doc objects as values\n",
        "    metadata_df : pd.DataFrame\n",
        "        DataFrame with columns: 'lastname', 'firstname', 'title', 'year', 'volume', 'ID', 'decade'\n",
        "    noun_input : str or list of str\n",
        "        Single noun lemma (e.g., 'liebe') or list of noun lemmata (e.g., ['liebe', 'leidenschaft'])\n",
        "    top_n : int\n",
        "        Number of most frequent adjectives to extract (default: 10)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    tuple : (pd.DataFrame, list)\n",
        "        - DataFrame with columns: filename, title, year, adjective, count, noun_count\n",
        "        - List of the top N adjectives found\n",
        "    \"\"\"\n",
        "    # Convert single noun to list for uniform processing\n",
        "    if isinstance(noun_input, str):\n",
        "        noun_list = [noun_input]\n",
        "    else:\n",
        "        noun_list = noun_input\n",
        "\n",
        "    # Convert to lowercase for case-insensitive matching\n",
        "    noun_list_lower = [noun.lower() for noun in noun_list]\n",
        "\n",
        "    # First pass: count all adjectives modifying any noun in the list across entire corpus\n",
        "    all_adjectives = Counter()\n",
        "\n",
        "    for file_id, doc in spacy_docs.items():\n",
        "        for token in doc:\n",
        "            # Check if this token is one of our target nouns\n",
        "            if token.lemma_.lower() in noun_list_lower and token.pos_ == 'NOUN':\n",
        "                # Find any dependent adjective\n",
        "                for child in token.children:\n",
        "                    #if child.dep_ == 'amod' and child.pos_ == 'ADJ':\n",
        "                    if child.pos_ == 'ADJ':\n",
        "                        all_adjectives[child.lemma_.lower()] += 1\n",
        "\n",
        "    # Get top N most frequent adjectives\n",
        "    top_adjectives = [adj for adj, count in all_adjectives.most_common(top_n)]\n",
        "\n",
        "    # Second pass: calculate frequencies per document\n",
        "    results = []\n",
        "\n",
        "    for file_id, doc in spacy_docs.items():\n",
        "        # Get metadata for this file\n",
        "        meta_row = metadata_df[metadata_df['ID'] == file_id]\n",
        "\n",
        "        if meta_row.empty:\n",
        "            continue\n",
        "\n",
        "        # Count adjectives modifying the target nouns\n",
        "        adjective_counts = Counter()\n",
        "        noun_count = 0\n",
        "\n",
        "        for token in doc:\n",
        "            # Check if this token is one of our target nouns\n",
        "            if token.lemma_.lower() in noun_list_lower and token.pos_ == 'NOUN':\n",
        "                noun_count += 1\n",
        "                #print('found noun:', token.text)\n",
        "                # Find adjective modifiers (amod dependency)\n",
        "                for child in token.children:\n",
        "                    #print('child dep:', child.dep_, 'pos:', child.pos_)\n",
        "                    #if child.dep_ == 'amod' and child.pos_ == 'ADJ':\n",
        "                    if child.pos_ == 'ADJ':\n",
        "                        #print('  found dependent adjective:', child.text)\n",
        "                        adjective_counts[child.lemma_.lower()] += 1\n",
        "\n",
        "        # Create a row for each top adjective found in this document\n",
        "        # (even if count is 0, we want to track that)\n",
        "        for adjective in top_adjectives:\n",
        "            count = adjective_counts.get(adjective, 0)\n",
        "            if noun_count > 0 or count > 0:  # Include if we have nouns or this adjective\n",
        "                results.append({\n",
        "                    'filename': file_id,\n",
        "                    'title': meta_row['title'].values[0],\n",
        "                    'year': meta_row['year'].values[0],\n",
        "                    'adjective': adjective,\n",
        "                    'count': count,\n",
        "                    'noun_count': noun_count\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(results), top_adjectives\n",
        "\n",
        "\n",
        "def get_top_adjectives_list(adj_df: pd.DataFrame, top_n: int = 10) -> list:\n",
        "    \"\"\"\n",
        "    Get the top N most frequent adjectives from the adjective dataframe.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    adj_df : pd.DataFrame\n",
        "        DataFrame returned by extract_adjective_modifiers_list()\n",
        "    top_n : int\n",
        "        Number of most frequent adjectives to return\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    list\n",
        "        List of top N adjectives\n",
        "    \"\"\"\n",
        "    total_counts = adj_df.groupby('adjective')['count'].sum().sort_values(ascending=False)\n",
        "    return total_counts.head(top_n).index.tolist()\n",
        "\n",
        "\n",
        "def plot_adjective_trends_list(adj_df: pd.DataFrame, top_adjectives: list,\n",
        "                               noun_input: Union[str, List[str]]):\n",
        "    \"\"\"\n",
        "    Create a plot showing adjective modifier trends over time for a noun or noun list.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    adj_df : pd.DataFrame\n",
        "        DataFrame returned by extract_adjective_modifiers_list()\n",
        "    top_adjectives : list\n",
        "        List of adjectives to plot (e.g., from get_top_adjectives_list())\n",
        "    noun_input : str or list of str\n",
        "        The noun(s) being analyzed\n",
        "    show_individual_texts : bool\n",
        "        If True, show individual text data points with titles; if False, show yearly means only\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    \n",
        "    .graph_objects.Figure\n",
        "        The figure object (will display automatically in Jupyter)\n",
        "    \"\"\"\n",
        "    # Filter for only the top adjectives\n",
        "    filtered_df = adj_df[adj_df['adjective'].isin(top_adjectives)].copy()\n",
        "\n",
        "    # Calculate relative frequency (per 100 noun occurrences)\n",
        "    # Handle division by zero\n",
        "    filtered_df['rel_freq'] = filtered_df.apply(\n",
        "        lambda row: (row['count'] / row['noun_count']) * 100 if row['noun_count'] > 0 else 0,\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Create figure\n",
        "    fig = go.Figure()\n",
        "\n",
        "\n",
        "    # Show individual texts as scatter points\n",
        "    for adj in top_adjectives:\n",
        "        adj_data = filtered_df[filtered_df['adjective'] == adj]\n",
        "\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=adj_data['year'],\n",
        "            y=adj_data['rel_freq'],\n",
        "            mode='markers',\n",
        "            name=adj,\n",
        "            text=adj_data['title'],\n",
        "            hovertemplate='<b>%{fullData.name}</b><br>' +\n",
        "                         '<b>%{text}</b><br>' +\n",
        "                         'Year: %{x}<br>' +\n",
        "                         'Frequency: %{y:.2f} per 100 occurrences<br>' +\n",
        "                         '<extra></extra>',\n",
        "            marker=dict(size=8, opacity=0.7)\n",
        "        ))\n",
        "\n",
        "    # Create title based on input\n",
        "    if isinstance(noun_input, str):\n",
        "        title_noun = f'\"{noun_input}\"'\n",
        "    else:\n",
        "        noun_str = ', '.join(noun_input[:3])\n",
        "        if len(noun_input) > 3:\n",
        "            noun_str += f', ... ({len(noun_input)} total)'\n",
        "        title_noun = f'[{noun_str}]'\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        title=f'Adjective Syntactic Dependents of {title_noun} Over Time',\n",
        "        xaxis_title='Year',\n",
        "        yaxis_title=f'Relative Frequency (per 100 noun occurrences)',\n",
        "        hovermode='closest',\n",
        "        height=600,\n",
        "        legend=dict(\n",
        "            title='Adjectives',\n",
        "            yanchor=\"top\",\n",
        "            y=0.99,\n",
        "            xanchor=\"right\",\n",
        "            x=0.99\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "def plot_adjective_trends_moving_avg_plotly(\n",
        "    adj_df: pd.DataFrame,\n",
        "    top_adjectives: list,\n",
        "    noun_input,\n",
        "    window_years: int = 10,\n",
        "    n_plot: int = 8,\n",
        "    value_col: str = \"rel_freq\",\n",
        "    show_points: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Plotly lineplot per year for adjective dependents + centered moving average window.\n",
        "\n",
        "    Expects adj_df to have at least: year, adjective, count, noun_count\n",
        "    If value_col (default: rel_freq) is missing, it will be computed as (count / noun_count) * 100.\n",
        "    \"\"\"\n",
        "\n",
        "    df = adj_df.copy()\n",
        "\n",
        "    # --- Ensure year is integer year (avoid datetime nanoseconds weirdness) ---\n",
        "    if \"year\" not in df.columns:\n",
        "        raise ValueError(\"adj_df must contain a 'year' column.\")\n",
        "\n",
        "    if pd.api.types.is_datetime64_any_dtype(df[\"year\"]):\n",
        "        df[\"year\"] = df[\"year\"].dt.year\n",
        "    else:\n",
        "        df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
        "\n",
        "    df = df.dropna(subset=[\"year\"])\n",
        "    df[\"year\"] = df[\"year\"].astype(int)\n",
        "\n",
        "    # --- Compute relative frequency if needed ---\n",
        "    if value_col not in df.columns:\n",
        "        if not {\"count\", \"noun_count\"}.issubset(df.columns):\n",
        "            raise ValueError(\n",
        "                f\"adj_df must contain '{value_col}' or both 'count' and 'noun_count'.\"\n",
        "            )\n",
        "        df[value_col] = df.apply(\n",
        "            lambda row: (row[\"count\"] / row[\"noun_count\"]) * 100 if row[\"noun_count\"] else 0,\n",
        "            axis=1,\n",
        "        )\n",
        "\n",
        "    # --- Filter adjectives ---\n",
        "    df = df[df[\"adjective\"].isin(top_adjectives)].copy()\n",
        "    if df.empty:\n",
        "        raise ValueError(\"After filtering by top_adjectives, no rows remain.\")\n",
        "\n",
        "    # --- Yearly aggregate (mean across texts) ---\n",
        "    yearly = (\n",
        "        df.groupby([\"year\", \"adjective\"])[value_col]\n",
        "          .mean()\n",
        "          .unstack(\"adjective\")\n",
        "          .sort_index()\n",
        "    )\n",
        "\n",
        "    # --- Moving average on yearly aggregates ---\n",
        "    moving = yearly.rolling(window=window_years, center=True, min_periods=1).mean()\n",
        "\n",
        "    # --- Limit to n_plot adjectives (keep original top_adjectives order if possible) ---\n",
        "    cols_in_data = [a for a in top_adjectives if a in moving.columns]\n",
        "    cols_to_plot = cols_in_data[:n_plot] if cols_in_data else list(moving.columns)[:n_plot]\n",
        "    moving_plot = moving[cols_to_plot].copy()\n",
        "\n",
        "    # --- Build title ---\n",
        "    if isinstance(noun_input, str):\n",
        "        title_noun = f'\"{noun_input}\"'\n",
        "    else:\n",
        "        noun_str = \", \".join(noun_input[:3])\n",
        "        if len(noun_input) > 3:\n",
        "            noun_str += f\", ... ({len(noun_input)} total)\"\n",
        "        title_noun = f\"[{noun_str}]\"\n",
        "\n",
        "    # --- Long format for plotly ---\n",
        "    moving_long = (\n",
        "        moving_plot.reset_index()\n",
        "                  .melt(id_vars=\"year\", var_name=\"adjective\", value_name=value_col)\n",
        "    )\n",
        "\n",
        "    # --- Plotly line chart ---\n",
        "    fig = px.line(\n",
        "        moving_long,\n",
        "        x=\"year\",\n",
        "        y=value_col,\n",
        "        color=\"adjective\",\n",
        "        markers=show_points,\n",
        "        title=f\"Top {min(n_plot, len(cols_to_plot))} Adjectives ‚Äì {window_years}-Year Moving Average ‚Äì {title_noun}\",\n",
        "        labels={\n",
        "            \"year\": \"Year\",\n",
        "            value_col: f\"{value_col} (moving avg, window={window_years}y)\",\n",
        "            \"adjective\": \"Adjective\",\n",
        "        },\n",
        "    )\n",
        "\n",
        "    # Make x axis show integer years cleanly (no scientific notation)\n",
        "    fig.update_xaxes(\n",
        "        tickmode=\"linear\",\n",
        "        dtick=10,          # change to 5/1 if you want denser ticks\n",
        "        tickformat=\"d\",\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        width=1000,\n",
        "        height=500,\n",
        "        legend_title_text=\"\",\n",
        "        hovermode=\"x unified\",\n",
        "        margin=dict(l=40, r=40, t=70, b=40),\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "    return yearly, moving\n",
        "\n",
        "\n",
        "def plot_top_adjective_ranking(\n",
        "    adj_df: pd.DataFrame,\n",
        "    top_n: int = 20,\n",
        "    noun_input=None,\n",
        "    metric: str = \"count\",   # \"count\" or \"share\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Show a simple ranking of the most frequent adjective modifiers.\n",
        "\n",
        "    metric:\n",
        "      - \"count\": total raw modifier counts across corpus\n",
        "      - \"share\": percentage share among all modifier counts (sums to 100)\n",
        "    \"\"\"\n",
        "    totals = (\n",
        "        adj_df.groupby(\"adjective\")[\"count\"]\n",
        "              .sum()\n",
        "              .sort_values(ascending=False)\n",
        "              .head(top_n)\n",
        "              .reset_index()\n",
        "              .rename(columns={\"count\": \"total_count\"})\n",
        "    )\n",
        "\n",
        "    if metric == \"share\":\n",
        "        totals[\"value\"] = (totals[\"total_count\"] / totals[\"total_count\"].sum()) * 100\n",
        "        xcol = \"value\"\n",
        "        xlabel = \"Share of all adjective modifiers (%)\"\n",
        "        hover = {\"total_count\": True, \"value\": \":.2f\"}\n",
        "    else:\n",
        "        totals[\"value\"] = totals[\"total_count\"]\n",
        "        xcol = \"value\"\n",
        "        xlabel = \"Total count (across corpus)\"\n",
        "        hover = {\"total_count\": True}\n",
        "\n",
        "    # Make a readable title noun\n",
        "    if isinstance(noun_input, str):\n",
        "        title_noun = f'\"{noun_input}\"'\n",
        "    elif isinstance(noun_input, list) and noun_input:\n",
        "        noun_str = \", \".join(noun_input[:3]) + (f\", ‚Ä¶ ({len(noun_input)})\" if len(noun_input) > 3 else \"\")\n",
        "        title_noun = f\"[{noun_str}]\"\n",
        "    else:\n",
        "        title_noun = \"\"\n",
        "\n",
        "    fig = px.bar(\n",
        "        totals[::-1],               # reverse for top at top in horizontal bar\n",
        "        x=xcol,\n",
        "        y=\"adjective\",\n",
        "        orientation=\"h\",\n",
        "        title=f\"Top {top_n} adjective modifiers of {title_noun}\",\n",
        "        labels={xcol: xlabel, \"adjective\": \"Adjective\"},\n",
        "        hover_data=hover,\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        height=450 + top_n * 12,  # scales nicely\n",
        "        margin=dict(l=120, r=40, t=60, b=40),\n",
        "        yaxis=dict(categoryorder=\"total ascending\"),\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "    return totals\n",
        "\n",
        "\n",
        "def show_top_adjectives_table(adj_df: pd.DataFrame, top_n: int = 20):\n",
        "    totals = (\n",
        "        adj_df.groupby(\"adjective\")[\"count\"]\n",
        "              .sum()\n",
        "              .sort_values(ascending=False)\n",
        "              .head(top_n)\n",
        "              .reset_index()\n",
        "              .rename(columns={\"count\": \"total_count\"})\n",
        "    )\n",
        "    totals[\"rank\"] = range(1, len(totals) + 1)\n",
        "    totals = totals[[\"rank\", \"adjective\", \"total_count\"]]\n",
        "\n",
        "    fig = go.Figure(data=[go.Table(\n",
        "        header=dict(values=list(totals.columns)),\n",
        "        cells=dict(values=[totals[c] for c in totals.columns])\n",
        "    )])\n",
        "    fig.update_layout(title=f\"Top {top_n} adjective modifiers (total counts)\", height=400)\n",
        "    fig.show()\n",
        "    #return totals\n",
        "\n",
        "\n",
        "def plot_top_adjectives_by_decade(adj_df: pd.DataFrame, metadata_df: pd.DataFrame, top_n: int = 8):\n",
        "    # attach decade via filename/ID\n",
        "    dec = metadata_df[[\"ID\", \"decade\"]].rename(columns={\"ID\": \"filename\"})\n",
        "    df = adj_df.merge(dec, on=\"filename\", how=\"left\").dropna(subset=[\"decade\"]).copy()\n",
        "\n",
        "    # totals per decade\n",
        "    g = (df.groupby([\"decade\", \"adjective\"])[\"count\"].sum().reset_index())\n",
        "    # find global top_n adjectives (across all decades)\n",
        "    top_adjs = (df.groupby(\"adjective\")[\"count\"].sum().sort_values(ascending=False).head(top_n).index.tolist())\n",
        "    g = g[g[\"adjective\"].isin(top_adjs)]\n",
        "\n",
        "    fig = px.bar(\n",
        "        g,\n",
        "        x=\"decade\",\n",
        "        y=\"count\",\n",
        "        color=\"adjective\",\n",
        "        barmode=\"group\",\n",
        "        title=f\"Top {top_n} adjective modifiers by decade (raw counts)\",\n",
        "        labels={\"count\": \"Count\", \"decade\": \"Decade\", \"adjective\": \"Adjective\"},\n",
        "    )\n",
        "    fig.update_layout(height=500, hovermode=\"x unified\")\n",
        "    fig.show()\n",
        "    #return g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afaf53ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "noun = \"Luft\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecc5e446",
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "adj_df, top_adjs = extract_dependent_adjective_list(annotated_docs, metadata_df, noun, top_n=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2d1e16e",
      "metadata": {
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "adj_df_alt, top_adjs_alt = extract_dependent_adjective_list(annotated_docs, metadata_df_alt, noun, top_n=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "263268b3",
      "metadata": {
        "tags": [
          "skip-execution",
          "hide-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# Save adj_df to CSV\n",
        "adj_df.to_csv(\"adj_df_luft.csv\", index=False)\n",
        "print(f\"Saved adj_df to adj_df_luft.csv ({len(adj_df)} rows)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6391cd07",
      "metadata": {
        "tags": [
          "skip-execution",
          "hide-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# Save adj_df_alt to CSV\n",
        "adj_df_alt.to_csv(\"adj_df_alt_luft.csv\", index=False)\n",
        "print(f\"Saved adj_df_alt to adj_df_alt_luft.csv ({len(adj_df_alt)} rows)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "727f60cc",
      "metadata": {},
      "source": [
        "## Laden gespeicherter Ergebnisse (Optional)\n",
        "\n",
        "Falls die Ergebnisse bereits extrahiert und als CSV gespeichert wurden, k√∂nnen sie hier geladen werden, anstatt die Extraktion erneut durchzuf√ºhren."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47c9017e",
      "metadata": {
        "tags": [
          "hide-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# Optional: Load previously saved results from CSV\n",
        "\n",
        "# Load adj_df\n",
        "adj_df = pd.read_csv(\"adj_df_luft.csv\")\n",
        "adj_df['year'] = pd.to_datetime(adj_df['year'])\n",
        "\n",
        "# Load adj_df_alt\n",
        "adj_df_alt = pd.read_csv(\"adj_df_alt_luft.csv\")\n",
        "adj_df_alt['year'] = pd.to_datetime(adj_df_alt['year'])\n",
        "\n",
        "# Recreate top_adjs lists from the dataframes\n",
        "top_adjs = adj_df.groupby('adjective')['count'].sum().sort_values(ascending=False).head(10).index.tolist()\n",
        "top_adjs_alt = adj_df_alt.groupby('adjective')['count'].sum().sort_values(ascending=False).head(10).index.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cefc1fb",
      "metadata": {},
      "source": [
        "## Analyse und Visualisierung"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a76fe70",
      "metadata": {},
      "source": [
        "### 1. Korpusweite H√§ufigkeiten adjektivischer Modifikatoren"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3a97bf7",
      "metadata": {},
      "source": [
        "Zun√§chst betrachten wir die Gesamtverteilung der adjektivischen Modifikatoren. Bevor zeitliche Entwicklungen analysiert werden, ist es sinnvoll, einen √úberblick dar√ºber zu gewinnen, welche Adjektive im gesamten Korpus am h√§ufigsten als syntaktische Modifikatoren der untersuchten Substantive auftreten. Diese aggregierte Betrachtung erlaubt es, dominante Beschreibungs- und Bewertungsmuster zu identifizieren und dient zugleich als Ausgangspunkt f√ºr die nachfolgenden diachronen Analysen.\n",
        "\n",
        "#### Sample 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9973a6bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "totals = plot_top_adjective_ranking(adj_df, top_n=20, noun_input=noun, metric=\"count\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d05f10b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "show_top_adjectives_table(adj_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca05ac6c",
      "metadata": {},
      "source": [
        "#### Sample 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b807201",
      "metadata": {},
      "outputs": [],
      "source": [
        "totals_alt = plot_top_adjective_ranking(adj_df_alt, top_n=20, noun_input=noun, metric=\"count\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64571781",
      "metadata": {},
      "outputs": [],
      "source": [
        "show_top_adjectives_table(adj_df_alt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5597660d",
      "metadata": {},
      "source": [
        "### 2. Diachrone Analyse adjektivisch-substantivischer Konstruktionen"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "442d3b54",
      "metadata": {},
      "source": [
        "Im n√§chsten Schritt wird die Analyse um eine diachrone Perspektive erweitert. Anstatt ausschlie√ülich korpusweite Gesamth√§ufigkeiten zu betrachten, wird nun untersucht, wie sich die Verwendung der zuvor identifizierten adjektivischen Modifikatoren im Zeitverlauf entwickelt. Die zeitliche Aggregation erlaubt es, Verschiebungen in Beschreibungs- und Bewertungsmustern nachzuzeichnen und diese mit historischen Prozessen in Beziehung zu setzen."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56e500c7",
      "metadata": {},
      "source": [
        "#### Sample 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82dfa785",
      "metadata": {},
      "outputs": [],
      "source": [
        "# yearly lineplots + moving average\n",
        "yearly_1, moving_1 = plot_adjective_trends_moving_avg_plotly(\n",
        "    adj_df, top_adjs, noun_input=noun, window_years=10, n_plot=8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfb5add0",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_top_adjectives_by_decade(adj_df, metadata_df, top_n=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40cbdb7a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# sample 1\n",
        "plot_adjective_trends_list(adj_df, top_adjs, noun)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "987681b4",
      "metadata": {},
      "source": [
        "#### Sample 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1906e9b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# NEW: yearly lineplots + moving average\n",
        "yearly_2, moving_2 = plot_adjective_trends_moving_avg_plotly(\n",
        "    adj_df_alt, top_adjs_alt, noun_input=noun, window_years=10, n_plot=8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98de5a1a",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_top_adjectives_by_decade(adj_df_alt, metadata_df_alt, top_n=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3835fc0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# sample 2\n",
        "plot_adjective_trends_list(adj_df_alt, top_adjs_alt, noun)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3b1d19a",
      "metadata": {},
      "source": [
        "## Add plots for specific words that we found"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2065f48c",
      "metadata": {},
      "source": [
        "TO BE CHANGED / UPDATED / CONTINUED"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
