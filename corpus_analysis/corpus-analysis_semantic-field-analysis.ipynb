{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7583a095-80ca-4c27-b4fe-99f8a83e7022",
   "metadata": {},
   "source": [
    "# üöÄ Analyse 1: Diachrone Frequenzdiagramme des semantischen Felds \"Luft\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dc89c3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Hinweise zur Ausf√ºhrung des Notebooks\n",
    "Dieses **Notebook** kann auf unterschiedlichen Levels erarbeitet werden (siehe Abschnitt [\"Technische Voraussetzungen\"](../introduction/introduction_requirements)): \n",
    "1. Book-Only Mode\n",
    "2. Cloud Mode: Daf√ºr auf üöÄ klicken und z.B. in Colab ausf√ºhren.\n",
    "3. Local Mode: Daf√ºr auf Herunterladen ‚Üì klicken und \".ipynb\" w√§hlen. \n",
    "\n",
    "## √úbersicht \n",
    "Im Folgenden werden die annotierten Dateien (CSV-Format) analysiert. Unser Ziel ist es, die Wort-/Lemma-H√§ufigkeiten des semantischen Felds \"Luft\" √ºber Zeit zu analysieren und zu visualisieren, um festzustellen, ob es, parallel zur industriellen Revolution, einen Anstieg im Auftreten des Felds gibt. \n",
    "\n",
    "Daf√ºr werden folgendene Schritte durchgef√ºhrt:\n",
    "1. Einlesen des Korpus, der Metadaten-Dateien f√ºr Korpora I und II und des semantischen Felds \"Luft\"\n",
    "2. Extraktion der Worth√§ufigkeiten und Plotten der Worth√§ufigkeiten f√ºr Korpus I\n",
    "3. Extraktion der Worth√§ufigkeiten und Plotten der Worth√§ufigkeiten f√ºr Korpus II\n",
    "4. Diskussion der Ergebnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5335d2b5-e7f0-4fe1-8dbf-2b5ea3336e9f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "  <summary><b>Informationen zum Ausf√ºhren des Notebooks ‚Äì Zum Ausklappen klicken ‚¨áÔ∏è</b></summary>\n",
    "  \n",
    "<b>Voraussetzungen zur Ausf√ºhrung des Jupyter Notebooks</b>\n",
    "<ol>\n",
    "<li> Installieren der Bibliotheken </li>\n",
    "<li> Pfad zu den Daten setzen</li>\n",
    "<li> Laden der Daten (z.B. √ºber den Command `wget` (s.u.))</li>\n",
    "</ol>\n",
    "Zum Testen: Ausf√ºhren der Zelle \"load libraries\" und der Sektion \"Einlesen der Daten\". </br>\n",
    "Alle Zellen, die mit üöÄ gekennzeichnet sind, werden nur bei der Ausf√ºhrung des Noteboos in Colab / JupyterHub bzw. lokal ausgef√ºhrt. \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5f0950-05d1-4fda-9bad-eca989d2d75b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "#  üöÄ Install libraries \n",
    "! pip install pandas spacy tqdm plotly numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ec0c33",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Union, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from tqdm.auto import tqdm\n",
    "from itables import show\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedc0959-7087-4353-9c17-665013944436",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Einlesen der Daten, Metadaten und der Grippe-Wortliste\n",
    "Um eine/mehrere Dateien mit Python bearbeiten zu k√∂nnen, m√ºssen die Dateien zuerst ausgew√§hlt werden, d.h der [Pfad](https://en.wikipedia.org/wiki/Path_(computing)) zu den Dateien wird gesetzt, und dann eingelesen werden. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7908f6a-c408-4a4a-a769-114c99d01f4a",
   "metadata": {},
   "source": [
    "### Einlesen des Korpus (CSV-Dateien)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5185fdd6-56a5-442e-a2ad-47367a2dd47e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "  <summary><b>Informationen zum Ausf√ºhren des Notebooks ‚Äì Zum Ausklappen klicken ‚¨áÔ∏è</b></summary>\n",
    "Zuerst wird der Ordner angelegt, in dem die CSV-Dateien gespeichert werden. Der Einfachheit halber wird die gleich Datenablagestruktur wie in dem <a href=\"https://github.com/quadriga-dk/Text-Fallstudie-1/tree/main\">GitHub Repository</a>, in dem die Daten gespeichert sind, vorausgesetzt. </br>\n",
    "Danach werden alle CSV-Dateien im Korpus heruntergeladen und gespeichert. Daf√ºr sind folgende Schritte n√∂tig:\n",
    "<ol>\n",
    "    <li>Es wird eine Liste erstellt, die die URLs zu den einzelnen CSV-Dateien beinhaltet.</li>\n",
    "    <li>Die Liste wird als txt-Datei gespeichert.</li>\n",
    "    <li>Alle Dateien aus der Liste werden heruntergeladen und in dem Ordner <i>../data/csv</i> gespeichert.</li>\n",
    "</ol>\n",
    "Sollten die Dateien schon an einem anderen Ort vorhanden sein, k√∂nnen die Dateipfade zu den Ordnern angepasst werden. </br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d9d65e-ef79-42fb-aba4-7ca0e97d8aa4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ Create data directory path\n",
    "corpus_dir = Path(\"../data/csv\")\n",
    "if not corpus_dir.exists():\n",
    "    corpus_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d6fdd-7226-431f-a3ab-9ba54da7a7ed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ Create download list \n",
    "github_api_txt_dir_path = \"https://api.github.com/repos/quadriga-dk/Text-Fallstudie-3/contents/data/csv\"\n",
    "txt_dir_info = requests.get(github_api_txt_dir_path).json()\n",
    "url_list = [entry[\"download_url\"] for entry in txt_dir_info]\n",
    "\n",
    "# üöÄ Write download list as txt file\n",
    "url_list_path = Path(\"github_csv_file_urls.txt\")\n",
    "with url_list_path.open('w') as output_txt:\n",
    "    output_txt.write(\"\\n\".join(url_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8d4d3-3e95-4e58-a90c-8fb9497b595c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è Only execute, if you haven't downloaded the files yet!\n",
    "# üöÄ Download all csv files ‚Äì this step will take a while (ca. 7 minutes)\n",
    "! wget -i github_csv_file_urls.txt -P ../data/spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad360f6-7453-4f39-99f7-7794608ff0a7",
   "metadata": {},
   "source": [
    "Setzen des Pfads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417616d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the path to csv files to be processed\n",
    "corpus_dir = Path(r\"../data/csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22863d76-5258-4b08-b29c-40b302200be3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Einlesen der CSV-Dateien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15179de7-3194-475b-97d2-34aeaa3fef22",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotated_docs = {}\n",
    "start = time()\n",
    "for fp in tqdm(corpus_dir.iterdir(), desc=\"Reading annotated data\"):\n",
    "    # check if the entry is a file, not a directory\n",
    "    if fp.is_file():\n",
    "        # check if the file has the correct suffix spacy\n",
    "        if fp.suffix == '.csv':\n",
    "            df = pd.read_csv(fp)\n",
    "            annotated_docs[fp.stem] = df\n",
    "took = time() - start\n",
    "print(f\"Loading the data took: {round(took, 4)} seconds\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75504fd3-3dca-4655-b169-51ba5f9b3ea8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Wie viele Dateien wurden eingelesen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5423cc59-a628-4b00-b054-55a60716c444",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(annotated_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e848450-4bc0-4073-a7f1-e61e848188fb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Wie sieht der Anfang der ersten Datei aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e65bc1-39b2-44d8-b629-c40ef4c668b9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotated_docs[list(annotated_docs.keys())[1]][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f49ed40-f735-4856-9b9d-0c60222b0778",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Einlesen der Metadaten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3428c9d8-5b4b-4f25-b286-b8f18dcde33b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "  <summary><b>Informationen zum Ausf√ºhren des Notebooks ‚Äì Zum Ausklappen klicken ‚¨áÔ∏è</b></summary>\n",
    "Zuerst wird der Ordner angelegt, in dem die Metadaten-Datei gespeichert wird. Wieder wird die gleich Datenablagestruktur wie in dem <a href=\"https://github.com/quadriga-dk/Text-Fallstudie-1/tree/main\">GitHub Repository</a> vorausgesetzt. </br>\n",
    "Der Text wird aus GitHub heruntergeladen und in dem Ordner <i>../data/metadata/</i> abgespeichert. </br>\n",
    "Der Pfad kann in der Variable <i>metadata_path</i> angepasst werden. Die einzulesende Datei muss die Endung `.csv` haben. </br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e236b6-ff73-4227-b8cb-180a8737f95f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ Create metadata directory path\n",
    "metadata_dir = Path(\"../metadata\")\n",
    "if not metadata_dir.exists():\n",
    "    metadata_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa5ade-eee2-48dc-81bb-2b84a2ceac16",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ Load the metadata file from GitHub \n",
    "! wget https://raw.githubusercontent.com/quadriga-dk/Text-Fallstudie-1/refs/heads/main/data/metadata/QUADRIGA_FS-Text-01_Data01_Corpus-Table.csv -P ../data/metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb88bfb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set path to metadata file\n",
    "metadata_path_1 = '../metadata/metadata_corpus-german_language_fiction_1820-1900_50-per-decade.csv'\n",
    "metadata_path_2 = '../metadata/metadata_corpus-german_language_fiction_1820-1900_50-per-decade_ALT.csv'\n",
    "\n",
    "def read_replace_metadata(fp):\n",
    "    corpus_metadata = pd.read_csv(fp)\n",
    "    corpus_metadata['year'] = pd.to_datetime(corpus_metadata['year'], format='%Y')\n",
    "    corpus_metadata = corpus_metadata.fillna(\"-\")\n",
    "    return corpus_metadata\n",
    "\n",
    "# read metadata file to pandas dataframe\n",
    "corpus_metadata_1 = read_replace_metadata(metadata_path_1)\n",
    "corpus_metadata_2 = read_replace_metadata(metadata_path_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d414bb4f-4b88-47ce-977a-9f9cf7cdd0ab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Wie sieht die Metadaten-Datei aus? (erste f√ºnf Zeilen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b09b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "show(corpus_metadata_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b5bf4b-bd61-4745-82f1-f8b019309c8b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Einlesen der Wortliste (Semantisches Feld \"Luft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d5b391-788a-4d98-9b27-4ab20750a659",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "  <summary><b>Informationen zum Ausf√ºhren des Notebooks ‚Äì Zum Ausklappen klicken ‚¨áÔ∏è</b></summary>\n",
    "Parallel zur Metadaten-Datei wird ein Ordner f√ºr die Wortlisten-Datein angelegt, die Datei wird aus GitHub geladen und in dem erstellten Ordner abgelegt.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0876d-44b2-464d-a210-33b68c71c380",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ Create word list directory path\n",
    "wordlist_dir = Path(\"../wordlist\")\n",
    "if not wordlist_dir.exists():\n",
    "    wordlist_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b96b4e-7ea5-4277-89fc-6e6f76bd7de1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ Load the wordlist file from GitHub \n",
    "! wget https://raw.githubusercontent.com/quadriga-dk/Text-Fallstudie-3/refs/heads/main/wordlist/luft_semantisches_feld.txt -P ../wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deee84f-89e9-431d-9ce0-b4319e6bd12d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_wordlist = Path(\"../wordlist/luft_semantisches_feld.txt\")\n",
    "semantic_field_nouns = list(set([word for word in path_to_wordlist.read_text().split(\"\\n\") if len(word) > 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ad341f-b7af-4821-9b0f-a58c0d4b0d66",
   "metadata": {},
   "source": [
    "Wie sieht die Wortliste aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fe88c8-c191-4dbd-a229-bb22aaea7391",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "semantic_field_nouns[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde3da39",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## H√§ufigkeiten der W√∂rter im semantischen Feld berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffec0eb-eee8-4042-8bab-3f202feb9b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noun_list_counts(annotated_docs: Dict, metadata_df: pd.DataFrame, \n",
    "                                  noun_list: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the combined relative frequency of a list of nouns for each text.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    spacy_docs : dict\n",
    "        Dictionary with file_ids as keys and spaCy Doc objects as values\n",
    "    metadata_df : pd.DataFrame\n",
    "        DataFrame with columns: 'lastname', 'firstname', 'title', 'year', 'ID', 'decade'\n",
    "    noun_list : list of str\n",
    "        List of noun lemmata to count together\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with columns: filename, title, year, total_freq, total_count, total_tokens\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for meta_row in metadata_df.itertuples():\n",
    "        file_id = meta_row.ID\n",
    "        \n",
    "        if file_id in annotated_docs:\n",
    "            doc = annotated_docs[file_id]\n",
    "        else:\n",
    "            print(f\"File {file_id} not in the corpus. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Count total tokens\n",
    "        total_tokens = len(doc)\n",
    "\n",
    "        # Skip empty texts\n",
    "        if total_tokens == 0:\n",
    "            continue\n",
    "            \n",
    "        # Count occurrences of the nouns in the list\n",
    "        nouns = doc[doc.POS == 'NOUN']\n",
    "        lemma_counts = nouns.Lemma.value_counts()\n",
    "        counts = lemma_counts.reindex(noun_list, fill_value=0)\n",
    "        specific_nouns = pd.DataFrame([counts.values], columns=counts.index)\n",
    "        \n",
    "        specific_nouns['ID'] = file_id\n",
    "        specific_nouns['total_count_tokens'] = total_tokens\n",
    "        results.append(specific_nouns)\n",
    "    combined_result = pd.concat(results, ignore_index=True)\n",
    "    metadata_result = pd.merge(metadata_df, combined_result, on=\"ID\")\n",
    "    \n",
    "    return metadata_result\n",
    "\n",
    "def get_relative_frequencies(df, semantic_field_nouns):\n",
    "    df['total_count_semantic_field'] = df[semantic_field_nouns].sum(axis=1)\n",
    "    df['relative_frequency'] = (df['total_count_semantic_field'] / df['total_count_tokens'])*100\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3419477a-8cc2-4152-8e98-3045aa096534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract frequencies for Corpus I and II\n",
    "count_1_df = extract_noun_list_counts(annotated_docs, corpus_metadata_1, semantic_field_nouns)\n",
    "count_2_df = extract_noun_list_counts(annotated_docs, corpus_metadata_2, semantic_field_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10e6dfb-3aaf-4273-b0a4-323d60782e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate relative frequencies for Corpus I and II\n",
    "freq_1_df = get_relative_frequencies(count_1_df, semantic_field_nouns)\n",
    "freq_2_df = get_relative_frequencies(count_2_df, semantic_field_nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac2aa51-42ba-4f1f-92e4-7926847f4dca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Ergebnisse f√ºr Korpus I angucken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b6d123-2bc0-45ec-b0bd-6620f2b7df74",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "show(freq_1_df[['lastname', 'firstname', 'title', 'year', 'total_count_tokens', 'total_count_semantic_field', 'relative_frequency']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3800544-8331-42ed-ac63-acddcef1c0a2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Ergebnisse f√ºr Korpus II angucken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfcfb44-91fe-47d3-ae9d-a55d19208606",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "show(freq_2_df[['lastname', 'firstname', 'title', 'year', 'total_count_tokens', 'total_count_semantic_field', 'relative_frequency']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db730e76-05aa-4227-a61f-2e4f9f81a7ca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### H√§ufigkeiten plotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89995ebb-b935-4571-8847-b9af32e4db68",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_noun_list_scatter(freq_df: pd.DataFrame, noun_list: List[str], \n",
    "                          show_trendline: bool = True, verbose: bool = False):\n",
    "    \"\"\"\n",
    "    Create a scatter plot showing the combined frequency of a noun list over time.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    freq_df : pd.DataFrame\n",
    "        DataFrame returned by extract_noun_list_frequencies()\n",
    "    noun_list : list of str\n",
    "        The list of nouns being analyzed (for the text)\n",
    "    show_trendline : bool\n",
    "        If True, add a linear regression trendline (default: True)\n",
    "    verbose : bool\n",
    "        If True, print diagnostic information about the trendline (default: False)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    plotly.graph_objects.Figure\n",
    "        The figure object (will display automatically in Jupyter)\n",
    "    \"\"\"\n",
    "    # Create scatter plot\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=freq_df['year'],\n",
    "        y=freq_df['relative_frequency'],\n",
    "        mode='markers',\n",
    "        name='Texts',\n",
    "        text=freq_df['title'],\n",
    "        customdata=np.column_stack((freq_df['total_count_semantic_field'], freq_df['lastname'])),\n",
    "        hovertemplate='<b>%{text}</b> (%{customdata[1]})<br>' +\n",
    "                     'Year: %{x|%Y}<br>' +\n",
    "                     'Frequency: %{y:.2f} per 100 tokens<br>' +\n",
    "                     'Total count: %{customdata[0]}<br>' +\n",
    "                     '<extra></extra>',\n",
    "        marker=dict(\n",
    "            size=8,\n",
    "            color='steelblue',\n",
    "            opacity=0.7,\n",
    "            line=dict(width=1, color='white')\n",
    "        )\n",
    "    ))\n",
    "    \n",
    "    # Add trendline if requested\n",
    "    if show_trendline:\n",
    "        # Calculate linear regression\n",
    "        \n",
    "        \n",
    "        # Convert year to numeric, handling datetime objects\n",
    "        if pd.api.types.is_datetime64_any_dtype(freq_df['year']):\n",
    "            # If datetime, extract the year\n",
    "            x = freq_df['year'].dt.year.values.astype(float)\n",
    "        else:\n",
    "            # Otherwise convert to numeric\n",
    "            x = pd.to_numeric(freq_df['year'], errors='coerce').values\n",
    "        \n",
    "        y = freq_df['relative_frequency'].values\n",
    "        \n",
    "        # Remove any NaN values\n",
    "        valid_idx = ~(np.isnan(x) | np.isnan(y))\n",
    "        x = x[valid_idx]\n",
    "        y = y[valid_idx]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Valid data points for trendline: {len(x)}\")\n",
    "            print(f\"Year range: {x.min():.0f} to {x.max():.0f}\")\n",
    "            print(f\"Frequency range: {y.min():.2f} to {y.max():.2f}\")\n",
    "        \n",
    "        if len(x) > 1:  # Need at least 2 points for a line\n",
    "            # Fit line: y = mx + b\n",
    "            m, b = np.polyfit(x, y, 1)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Trendline equation: y = {m:.6f}x + {b:.4f}\")\n",
    "                print(f\"Slope interpretation: {'increasing' if m > 0 else 'decreasing' if m < 0 else 'flat'} trend\")\n",
    "            \n",
    "            # Create trendline\n",
    "            x_trend = np.array([x.min(), x.max()])\n",
    "            y_trend = m * x_trend + b\n",
    "            \n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=x_trend,\n",
    "                y=y_trend,\n",
    "                mode='lines',\n",
    "                name='Trend',\n",
    "                line=dict(color='red', width=2, dash='dash'),\n",
    "                hovertemplate='Trendline<br>Year: %{x}<br>%{y:.2f}<extra></extra>'\n",
    "            ))\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"Warning: Not enough valid data points to draw trendline (need at least 2)\")\n",
    "    \n",
    "    # Create a readable noun list for the title\n",
    "    noun_list = list(noun_list)\n",
    "    noun_list_str = ', '.join(noun_list[:5])\n",
    "    if len(noun_list) > 5:\n",
    "        noun_list_str += f', ... ({len(noun_list)} total)'\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f'Relative Frequenz des semantischen Felds',\n",
    "        xaxis_title='Jahr',\n",
    "        yaxis_title='Relative Frequenz (pro 100 Tokens)',\n",
    "        hovermode='closest',\n",
    "        height=600,\n",
    "        showlegend=show_trendline\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d557c071-1a88-4ba2-b026-a763bc27b1b7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create scatter plot\n",
    "plot_noun_list_scatter(count_1_df, semantic_field_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f093ffc-1382-495f-b433-618a956f93b0",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create scatter plot\n",
    "plot_noun_list_scatter(freq_2_df, semantic_field_nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2792d98-5ac4-46ab-805a-6ef5d7366255",
   "metadata": {},
   "source": [
    "### Entwicklung der h√§ufigsten W√∂rter des semantisches Felds anzeigen\n",
    "* mean > 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5c5085-4c57-4569-b859-38b4d94bf89e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "def filter_df_by_mean_threshold(df, semantic_field_nouns, threshold=1):\n",
    "    # Find which checked columns pass the threshold\n",
    "    passing_cols = [col for col in semantic_field_nouns if df[col].mean() > threshold]\n",
    "    \n",
    "    # Keep passing columns plus all columns that weren't checked\n",
    "    other_cols = [col for col in df.columns if col not in semantic_field_nouns]\n",
    "    df_filtered = df[other_cols + passing_cols]\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "def plot_single_terms(df_filtered, semantic_field_nouns):\n",
    "    # Calculate relative frequencies for each term\n",
    "    terms = [col_name for col_name in df_filtered.columns if col_name in semantic_field_nouns]\n",
    "    for term in terms:\n",
    "        df_filtered[f'{term}_relative'] = (df_filtered[term] / df_filtered['total_count_tokens']) * 100\n",
    "    \n",
    "    # Melt the dataframe to long format\n",
    "    plot_data = df_filtered.melt(\n",
    "        id_vars=['year', 'title', 'lastname', 'total_count_tokens'],\n",
    "        value_vars=[f'{term}_relative' for term in terms],\n",
    "        var_name='Term',\n",
    "        value_name='Relative_Frequency'\n",
    "    )\n",
    "    \n",
    "    # Clean up term names\n",
    "    plot_data['Term'] = plot_data['Term'].str.replace('_relative', '')\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    colors = ['steelblue', 'coral', 'seagreen', 'mediumpurple', 'goldenrod']\n",
    "    term_colors = dict(zip(terms, colors))\n",
    "    \n",
    "    for term in terms:\n",
    "        term_data = plot_data[plot_data['Term'] == term].sort_values('year')\n",
    "        \n",
    "        # Add scatter points\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=term_data['year'],\n",
    "            y=term_data['Relative_Frequency'],\n",
    "            mode='markers',\n",
    "            name=term,\n",
    "            text=term_data['title'],\n",
    "            customdata=term_data['lastname'],\n",
    "            hovertemplate='<b>%{text}</b> (%{customdata})<br>' +\n",
    "                         'Year: %{x|%Y}<br>' +\n",
    "                         f'{term} Frequency: ' + '%{y:.4f} per 100 tokens<br>' +\n",
    "                         '<extra></extra>',\n",
    "            marker=dict(size=6, color=term_colors[term], opacity=0.5),\n",
    "            showlegend=True\n",
    "        ))\n",
    "        \n",
    "        # Add smoothed trend line (if enough data points)\n",
    "        if len(term_data) > 5:\n",
    "            try:\n",
    "                smoothed = savgol_filter(term_data['Relative_Frequency'], \n",
    "                                        window_length=min(11, len(term_data) if len(term_data) % 2 == 1 else len(term_data)-1), \n",
    "                                        polyorder=2)\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=term_data['year'],\n",
    "                    y=smoothed,\n",
    "                    mode='lines',\n",
    "                    name=f'{term} (trend)',\n",
    "                    line=dict(color=term_colors[term], width=2),\n",
    "                    showlegend=False,\n",
    "                    hoverinfo='skip'\n",
    "                ))\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Relative Frequenz des gefilterten semantischen Felds √ºber Zeit',\n",
    "        xaxis_title='Jahr',\n",
    "        yaxis_title='Frequenz pro 100 Tokens',\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e00ba-ebcc-4908-85ac-2b1bdb132457",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "no-stderr"
    ]
   },
   "outputs": [],
   "source": [
    "filtered_1 = filter_df_by_mean_threshold(freq_1_df, semantic_field_nouns)\n",
    "plot_single_terms(filtered_1, semantic_field_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b61c1-f3af-44cc-a6da-22622476d331",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "no-stderr"
    ]
   },
   "outputs": [],
   "source": [
    "filtered_2 = filter_df_by_mean_threshold(freq_2_df, semantic_field_nouns)\n",
    "plot_single_terms(filtered_2, semantic_field_nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afc39d2-2f83-47b1-99cb-e2d7e259e43b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Schreiben der Ergebnisse \n",
    "Die Ergebnisse werden als Tabellen (`.csv`-Dateien) gespeichert, so kann die Erstellung der Abbildungen unbah√§ngig von diesem Notebook nachvollzogen werden und die werden Ergebnisse so nachnutzbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57facca-f9ec-463b-8dad-80765c5f3fe2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_dir = Path(\"results/\")\n",
    "if not result_dir.exists():\n",
    "    result_dir.mkdir()\n",
    "\n",
    "result_path_1 = result_dir / \"results-corpus-german_language_fiction_1820-1900_50-per-decade-I.csv\"\n",
    "result_path_2 = result_dir / \"results-corpus-german_language_fiction_1820-1900_50-per-decade-II.csv\"\n",
    "\n",
    "freq_1_df.to_csv(result_path_1, index=False)\n",
    "freq_2_df.to_csv(result_path_2, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffeb48a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Diskussion der H√§ufigkeitsanalyse\n",
    "\n",
    "Die Analyse der relativen H√§ufigkeiten zeigt, dass deutschsprachige literarische Texte des 19. Jahrhunderts **nicht** vermehrt √ºber Luft und Luft-verwandte Begriffe sprechen, sondern der Trend in beiden Subkorpora stagniert. Zwar gibt es Ausrei√üer wie z.B. *Das Dorf im Gebirge* (von Hofmannsthal) oder *Das Schattenspiel* von Flaischlen, die beide \n",
    "\n",
    "Es gibt mehrere Deutungsans√§tze dieses Ergebnisses: Zum einen kann es sein, dass deutschsprachige Literatur die durch die revolutionelle Revolution herbeigef√ºhrte Ver√§nderung der Luftqualit√§t tats√§chlich nicht reflektiert. Zum anderen ist es m√∂glich, dass unsere Operationalisierung zu kurz gegriffen ist, z.B. da abnehmende Luftqualit√§t subtiler angedeutet werden k√∂nnte oder die relative H√§ufigkeit keine gute Metrik f√ºr die Importanz der Thematik ist. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
