{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8962c4f2-7f36-4b28-b0d5-33a9bcff60e1",
   "metadata": {},
   "source": [
    "# üöÄ Korpusverarbeitung ‚Äì Annotation mit spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaf3791",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Hinweise zur Ausf√ºhrung des Notebooks\n",
    "Dieses Notebook kann auf unterschiedlichen Levels erarbeitet werden (siehe Abschnitt [\"Technische Voraussetzungen\"](../introduction/introduction_requirements)): \n",
    "1. Book-Only Mode\n",
    "2. Cloud Mode: Daf√ºr auf üöÄ klicken und z.B. in Colab ausf√ºhren.\n",
    "3. Local Mode: Daf√ºr auf Herunterladen ‚Üì klicken und \".ipynb\" w√§hlen. \n",
    "\n",
    "## √úbersicht\n",
    "Im Folgenden wird exemplarisch der Roman \"Feldblumen\" von Adalbert Stifter (txt-Datei) mit der Bibliothek [spaCy](https://spacy.io) annotiert.\n",
    "\n",
    "Es werden folgendene Schritte durchgef√ºhrt:\n",
    "1. Einlesen des Texts\n",
    "3. Worth√§ufigkeiten ohne echte Tokenisierung\n",
    "   * Aufteilen des Texts in W√∂rter auf Grundlage von Leerzeichen\n",
    "   * Abfrage von H√§ufigkeiten\n",
    "4. Annotation mit spaCy\n",
    "   * Laden des Sprachmodells\n",
    "   * Analysekomponenten ausw√§hlen\n",
    "   * Text annotieren: Lemmatisierung, POS-Tagging, Dependency Parsing\n",
    "   * Worth√§ufigkeiten anzeigen\n",
    "5. Vorl√§ufige Experimente zur Adjektiv-Extraktion\n",
    "6. Annotation speichern\n",
    "7. Prozess f√ºr die gesamten Korpora ausf√ºhren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da21b95-0aa9-43e0-8799-0adc631ebf9c",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<details>\n",
    "  <summary><b>Informationen zum Ausf√ºhren des Notebooks ‚Äì Zum Ausklappen klicken ‚¨áÔ∏è</b></summary>\n",
    "  \n",
    "<b>Voraussetzungen zur Ausf√ºhrung des Jupyter Notebooks</b>\n",
    "<ol>\n",
    "<li> Installieren der Bibliotheken </li>\n",
    "<li>2. Laden der Daten (z.B. √ºber den Command `wget` (s.u.))</li>\n",
    "<li>3. Pfad zu den Daten setzen</li>\n",
    "</ol>\n",
    "Zum Testen: Ausf√ºhren der Zelle \"load libraries\" und der Sektion \"Einlesen des Texts\". </br>\n",
    "Alle Zellen, die mit üöÄ gekennzeichnet sind, werden nur bei der Ausf√ºhrung des Noteboos in Colab / JupyterHub bzw. lokal ausgef√ºhrt. \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c15d4a-f4ed-48e8-b4db-fdf8f60d2507",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "skip-execution",
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "#  üöÄ Install libraries \n",
    "! pip install tqdm pandas numpy spacy bokeh ipython==7.23.1\n",
    "\n",
    "#  üöÄ Load german language model for annotation\n",
    "! python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d33ac2-97dd-45fd-99b5-dac91fdde243",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# load libraries \n",
    "import json\n",
    "import typing\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from collections import OrderedDict, Counter\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import CustomJS, TextInput, Div"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be81998d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Einlesen des Texts\n",
    "Um eine Datei mit Python bearbeiten zu k√∂nnen, muss die Datei zuerst ausgew√§hlt, d.h der [Pfad](https://en.wikipedia.org/wiki/Path_(computing)) zur Datei wird gesetzt, und dann eingelesen werden. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560bed39-3c81-4caa-972f-cbc68471b6ff",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "<details>\n",
    "  <summary><b>Informationen zum Ausf√ºhren des Notebooks ‚Äì Zum Ausklappen klicken ‚¨áÔ∏è</b></summary>\n",
    "Zuerst wird der Ordner angelegt, in dem die Textdateien gespeichert werden. Der Einfachheit halber wird die gleich Datenablagestruktur wie in dem <a href=\"https://github.com/quadriga-dk/Text-Fallstudie-3/tree/main\">GitHub Repository</a>, in dem die Daten gespeichert sind, vorausgesetzt. </br>\n",
    "Der Text wird aus GitHub heruntergeladen und in dem Ordner <i>../data/txt/</i> abgespeichert. </br>\n",
    "Der Pfad kann in der Variable <i>text_path</i> angepasst werden. Die einzulesenden Daten m√ºssen die Endung `.txt` haben. </br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e44bae-673b-4cc4-8133-34da0ca8d4b1",
   "metadata": {},
   "source": [
    "#### Pfad setzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ccb971-f3b8-4b1a-851a-786fc86a9ace",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "skip-execution",
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ Create data directory path\n",
    "corpus_dir = Path(\"../data/txt\")\n",
    "if not corpus_dir.exists():\n",
    "    corpus_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da277ff-8e06-46b7-8ae3-2af076036d37",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ Load the txt file from GitHub \n",
    "! wget https://raw.githubusercontent.com/quadriga-dk/Text-Fallstudie-3/refs/heads/main/data/txt/Adalbert_Stifter_-_Feldblumen_(1841).txt -P ../data/txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad5cbf8-a9dc-4788-bd0e-f95bdfa57e64",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the path to file to be processed\n",
    "text_path = Path(\"../data/txt/Adalbert_Stifter_-_Feldblumen_(1841).txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1700d8d7-56e4-49a9-bbc6-0ae91adf2142",
   "metadata": {},
   "source": [
    "#### Text einlesen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa6bd5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read text and print some parts of the text\n",
    "if text_path.is_file():\n",
    "    text = text_path.read_text()\n",
    "    print(f\"Textauszug:\\n {text[120:230]}\")\n",
    "else:\n",
    "    print(\"The file path does not exist. Set the variable text_path to an existing path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df56e18-251c-458d-8933-1e0ec257c461",
   "metadata": {},
   "source": [
    "Im Textauszug ist erkennbar, dass der Text die Abs√§tze aus dem Text einer Print-Ausgabe entsprechen. Das ist f√ºr die automatische Prozessierung mit **spaCy** irrelevant, da die Abs√§tze (kodiert durch `\\n`) nicht als semantische Einheit gesehen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6d22bb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Worth√§ufigkeiten ohne echte Tokenisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d76a71-2035-4e50-ab55-7604e60deef7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Text in W√∂rter aufteilen\n",
    "Der einfachste Weg einen Text automatisch in W√∂rter aufzuteilen, ist anzunehmen, dass W√∂rter durch Leerzeichen getrennt sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07258cc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split the text into words by space\n",
    "words = text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444ddd15-3fce-47ff-b4c9-e8ab1e19c3ca",
   "metadata": {},
   "source": [
    "Wie lang ist der Text in Worten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b810a517-4db4-42ec-ab80-e1d9fcf6ee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694298bd-8e8f-4570-b053-f3e7b42f77d8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Pr√ºfen**: Wie sieht die Wortliste aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b37fa42-ae7a-4bca-8b01-36cd1444e31a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print the 7th up the 79th words\n",
    "words[7:79]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d542d5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Wie viele W√∂rter gibt es insgesamt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ee91df",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print the length of the word list\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd4e5d1-4a04-44e9-9acb-d178549ef8a9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Wie zu sehen ist, hat diese Art der \"falschen\" Tokenisierung den Nachteil, dass Satzzeichen nicht von W√∂rtern abgetrennt werden. \\\n",
    "Die Wortanzahl ist dementsprechend auch nicht akkurat. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca89700-b85b-4666-8a2e-0e6fba45d257",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Anzeigen von Worth√§ufigkeiten\n",
    "Auf Grundlage dieser Wortliste kann trotzdem schon eine erste basale H√§ufigkeitenabfrage erfolgen. Daf√ºr werden die W√∂rter zuerst gez√§hlt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecbc10d-78ed-4cba-9927-c2c145db18bf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count the words with Counter and save the result to a variable\n",
    "word_frequencies = Counter(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621342ad-0a89-4066-8b49-d8f89250ae7c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "<details>\n",
    "  <summary><b>Informationen zum Ausf√ºhren des Notebooks ‚Äì Zum Ausklappen klicken ‚¨áÔ∏è</b></summary>\n",
    "Um die H√§ufigkeit nur mit Python abzufragen, kann folgende Zeile ausgef√ºhrt werden:\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea0f435-d0c8-4409-9c55-6c29514c0b29",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# üöÄ get the number of the word \"Luft\" in the word frequencies \n",
    "word_frequencies[\"Luft\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3685447-ba0b-4c50-9490-99148bc743e5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Dann kann die H√§ufigkeit abgefragt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7d2cc1-15b8-457e-82d5-7b27e37e7a7b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Ensure Bokeh output is displayed in the notebook\n",
    "output_notebook()\n",
    "\n",
    "# Convert the dictionary to a JSON string to be passed to javascript\n",
    "word_freq_json = json.dumps(word_frequencies)\n",
    "\n",
    "# Create the text input widget\n",
    "text_input = TextInput(value='', title=\"Geben Sie ein Wort ein:\")\n",
    "\n",
    "# Create a Div to display the frequency\n",
    "frequency_display = Div(text=\"H√§ufigkeit: \")\n",
    "\n",
    "# JavaScript callback to update the frequency display\n",
    "# Only needed for graphical interface \n",
    "callback = CustomJS(args=dict(frequency_display=frequency_display, text_input=text_input), code=f\"\"\"\n",
    "    var word = text_input.value.trim();\n",
    "\n",
    "    // Parse the word frequency dictionary from Python\n",
    "    var word_freq = {word_freq_json};\n",
    "\n",
    "    var frequency = word in word_freq ? word_freq[word] : \"Nicht gefunden\";\n",
    "    frequency_display.text = \"H√§ufigkeit: \" + frequency;\n",
    "\"\"\")\n",
    "\n",
    "text_input.js_on_change('value', callback)\n",
    "\n",
    "# Layout and display\n",
    "layout = column(text_input, frequency_display)\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b158ecb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Annotation mit spaCy\n",
    "Um eine pr√§zisere Einteilung in W√∂rter zu erhalten (Tokenisierung) und um flektierte W√∂rter aufeinander abbildbar zu machen (Lemmatisierung), wird der Text im folgenden durch die Bibliothek [spaCy](https://spacy.io/) annotiert. In der darauffolgenden Analyse sollen au√üerdem Adjektiv-Nomen Paare extrahiert werden, \n",
    "\n",
    "Daf√ºr werden folgende Schritte ausgef√ºhrt:\n",
    "1. Das sprachspezifische Modell wird geladen. Wir arbeiten mit dem weniger akkuraten aber schnellsten spaCy Modell `de_core_news_sm`. \n",
    "2. F√ºr eine erh√∂hte Annotationsgeschwindigkeit werden nur bestimmte Analysekomponenten geladen. Dies ist vor allem f√ºr gr√∂√üere Textmengen sinnvoll.\n",
    "3. Der Text wird annotiert und die Token sowie die dazugeh√∂rigen Lemmata werden extrahiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69caa926-5e4f-4a7f-bc27-3b4967c4b3e6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Sprachmodell laden\n",
    "Das sprachspezifische Modell wird geladen. Es handelt sich dabei um das am wenigsten akkurate aber schnellste Modell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52bea2b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('de_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49a88c3-4beb-42ea-9f88-290a92ce7cc0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Analysekomponenten ausw√§hlen\n",
    "Es werden einige Analysekomponent wie z. B. das Aufteilen des Texts in S√§tze (sentencizer) oder die [Named Entity Recognition](https://en.wikipedia.org/wiki/Named-entity_recognition) (ner) ausgeschlossen, da diese f√ºr die Tokenisierung und die Lemmatisierung sowie f√ºr das POS-Tagging und Dependency Parsing nicht ben√∂tigt werden. Der Auschluss der Komponenten erh√∂ht die Annotationsgeschwindikgeit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb49918",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "disable_components = ['ner', 'attribute_ruler', 'sentencizer']\n",
    "nlp.max_length = 5200000 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bec70c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Annotieren der Texte: Token, Lemma, POS, Dependenzen\n",
    "Der ausgew√§hlte Text wird mit spaCy annotiert und liegt dann in einem spaCy-eigenen Datenformat, dem sogenannten `Doc` vor. Das `Doc` ist eine praktische Datenstruktur, in der sich die Annotation leicht navigieren lassen. \n",
    "So kann zu jedem Token das dazugeh√∂rige Lemma, POS-Tag und die Dependenzannotation abfragen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8800a679-11c9-4aff-a509-ccc63d9fb6e4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the current time to display how long the annotation took\n",
    "current = time()\n",
    "\n",
    "# annotate with spacy\n",
    "doc = nlp(text)\n",
    "\n",
    "# calculate how long the annotation and extraction took and print result\n",
    "took = time() - current\n",
    "print(f\"Die Annotation hat {round(took, 2)} Sekunden gedauert.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e81b84-22d1-42c9-8612-99ac29503597",
   "metadata": {},
   "source": [
    "Wie lang ist der Text jetzt (in Worten)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe3134c-3a96-47a1-86c5-d0c738074f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dccb8ff-e04c-4ad1-b00c-5ffd35b9f873",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Die Annotationen lassen sich dann wie folgt anzeigen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a351b8d-a2eb-4f6e-95c8-73b6ba0daed5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print extract of the annotation\n",
    "print(f\"Token\\tLemma\\tPOS\\tDependency Head\\tDependency Tag\")\n",
    "for token in doc[89:110]:\n",
    "    print(f\"{token.text}\\t{token.lemma_}\\t{token.pos_}\\t{token.head}\\t{token.dep_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afc7b34-e1c8-41f6-aa58-364ef192f381",
   "metadata": {},
   "source": [
    "Um herauszufinden, wof√ºr die einzelnen Tags stehen, k√∂nnen wir spaCy's `.explain` Methode benutzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b259f5-280f-436e-8b68-3e8776f3d4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain(\"mnr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8160c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Worth√§ufigkeit mit echter Tokenisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbf9300-6a9b-41f7-8b4b-3fbfb1adea04",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Durch die Tokenisierung wurden z. B. Satzzeichen von W√∂rtern abgetrennt. An der Textl√§nge l√§sst sich dies schon erkennen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a224b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the lemmata \n",
    "text_tokenized = [token.lemma_ for token in doc]\n",
    "\n",
    "# print the length\n",
    "len(text_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640ab432-cfce-4599-ac77-35d72176cca4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Auf Grundlage des tokenisierten und lemmatisierten Texts, kann die H√§ufigkeitenabfrage erneut augef√ºhrt werden. Da durch die Lemmatisierung flektierte Wortformen auf die Grundformen zur√ºckgef√ºhrt wurden, erwarten wir, dass die H√§ufigkeit einer Wortgrundform im Gegensatz zur vorherigen Abfrage erh√∂ht ist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d142db-b63f-41ba-8651-6ef8faeb9d6b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count the words with Counter and save the result to a variable\n",
    "token_frequencies = Counter(text_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083e5550-a2bd-4553-a253-0826009abe53",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "<details>\n",
    "  <summary><b>Informationen zum Ausf√ºhren des Notebooks ‚Äì Zum Ausklappen klicken ‚¨áÔ∏è</b></summary>\n",
    "Um die H√§ufigkeit nur mit Python abzufragen, kann folgende Zeile ausgef√ºhrt werden:\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3127479-7a15-4c35-9bd9-00ac1b348dc6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Wir k√∂nnen die H√§ufigkeit des Worts \"Luft\" abfragen oder unten nach weiteren W√∂rtern suchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baeaaf5-57a2-4b7e-ad03-2ee1b525016b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# üöÄ get the number of the word \"Grippe\" in the word frequencies \n",
    "token_frequencies[\"Luft\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f710e18-9fbd-4e9e-8b70-09181b751a70",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Ensure Bokeh output is displayed in the notebook\n",
    "output_notebook()\n",
    "\n",
    "# Convert the dictionary to a JSON string\n",
    "tok_freq_json = json.dumps(token_frequencies)\n",
    "\n",
    "# Create the text input widget\n",
    "token_input = TextInput(value='', title=\"Geben Sie ein Wort ein:\")\n",
    "\n",
    "# Create a Div to display the frequency\n",
    "token_frequency_display = Div(text=\"H√§ufigkeit: \")\n",
    "\n",
    "# JavaScript callback to update the frequency display\n",
    "# Only needed for graphical interface \n",
    "tok_callback = CustomJS(args=dict(frequency_display=token_frequency_display, text_input=token_input), code=f\"\"\"\n",
    "    var tok = text_input.value.trim();\n",
    "\n",
    "    // Parse the word frequency dictionary from Python\n",
    "    var word_freq = {tok_freq_json};\n",
    "\n",
    "    var frequency = tok in word_freq ? word_freq[tok] : \"Nicht gefunden\";\n",
    "    frequency_display.text = \"H√§ufigkeit: \" + frequency;\n",
    "\"\"\")\n",
    "\n",
    "token_input.js_on_change('value', tok_callback)\n",
    "\n",
    "# Layout and display\n",
    "layout = column(token_input, token_frequency_display)\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c101e8-08e9-420f-accf-960609c2aec0",
   "metadata": {},
   "source": [
    "### Luft-Adjektive \n",
    "In einem weiteren Schritt k√∂nnen wir die Adjektive extrahieren, die mit dem Nomen Luft in Verbindung stehen. Wir machen dabei Gebrauch von den Dependenzstrukturen, die sich durch das spaCy-eigene `Doc` einfach navigieren lassen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6120a1e-e16b-420f-b828-3a03c7d7cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjectives = []\n",
    "for token in doc:\n",
    "    # Find the target noun\n",
    "    if token.lemma_ == \"Luft\" and token.pos_ == \"NOUN\":\n",
    "        # find attributive adjectives (direct children of the noun)\n",
    "        for child in token.children:\n",
    "            if child.pos_ == \"ADJ\":\n",
    "                adjectives.append(child.lemma_)\n",
    "        \n",
    "        # find predicative adjectives\n",
    "        # The noun should be subject (sb) of a copula verb\n",
    "        if token.dep_ == \"sb\":  # check if noun is subject\n",
    "            head = token.head # get verb\n",
    "            # Check if head is a copula (sein, werden, bleiben, etc.)\n",
    "            if head.pos_ in [\"AUX\", \"VERB\"] and head.lemma_ in [\"sein\", \"werden\", \"bleiben\"]:\n",
    "                # Find predicate adjectives (children of the copula)\n",
    "                for child in head.children:\n",
    "                    if child.pos_ == \"ADJ\" and child.dep_ == \"pd\":  # predicate\n",
    "                        adjectives.append(child.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db675d85-c368-4afc-b66c-ba500076ee6e",
   "metadata": {},
   "source": [
    "Wir lassen uns die Anzahl der Adjektive anzeigen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa86fc4-4cdd-4175-b908-048137c44f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(adjectives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e323fc6-a4e3-41d4-969f-e360e55eaea3",
   "metadata": {},
   "source": [
    "Und lassen die Adjektive z√§hlen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e1a8dd-6bd2-4b3b-836a-a81340d5691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjectives_counted = Counter(adjectives)\n",
    "adjectives_counted.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be05acc-7194-4f81-9894-09bcd6cd7a14",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Aus den 16 Vorkommen von Luft (s.o.), werden 8 durch Adjektive genauer beschrieben, darunter lassen sich sowohl positive Adjektive wie \"rein\" und \"weich\" finden als auch negative Adjektive wie \"finster\". In *Feldblumen* zeichnet sich mit dieser Minimalnanalyse noch kein klares Bild √ºber die Konnotation von Luft ab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6402923a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Annotationen speichern\n",
    "Um den annotierten Text zu speichern, muss zuerst das Speicher-Format festgelegt. F√ºr die Speicherung von relativen Daten (wie ein Wort und die unterschiedlichen Annotationen des Worts) eignet sich das Tabellenformat gut. F√ºr die weitere Prozessierung ist es allerdings von Vorteil die spaCy-spezifischen Funktionen nutzen zu k√∂nnen, um die Dependenz-Annotationen zu navigieren (wie in dem Beispiel oben). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee92bd2c-52c0-4f14-a147-396299261f36",
   "metadata": {},
   "source": [
    "```{admonition} Datei-Format und Interoperabilit√§t \n",
    ":class: caution\n",
    "Wenn die Annotationen nur im spaCy-eigenen Format gespeichert werden, sind wir von spaCy abh√§ngig, um die Dateien wieder auslesen zu k√∂nnen. Das Format ist dementsprechend weniger interoperabel. Um die Reproduzierbarkeit der Annotation sicherzustellen, sollte:\n",
    "* dokumentiert werden, mit welcher spaCy-Version die Dateien erstellt wurden\n",
    "* im bestem Fall die Dateien zus√§tzlich in einem platform-unabh√§ngigen, textbasierten Format wie CSV abgespeichert werden. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b115970-f3c5-4a15-9fe3-cf41a6572d05",
   "metadata": {},
   "source": [
    "Deswegen speichern wir die Annotationen sowohl √ºber die von spaCy dazu bereitgestellten Methoden, um sie dann wieder in spaCy laden zu k√∂nnen als auch im Tabellenformat, da Tabellen unabh√§ngig von einer spezifischen Bibliothek / einem spezifischen Programm ge√∂ffnet werden k√∂nnen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7a122e-8964-42e3-96a2-c55299c661cc",
   "metadata": {},
   "source": [
    "### Annotationstabelle erstellen\n",
    "Zuerst erstellen wir aus den Annotationen eine Tabelle, daf√ºr legen wir folgende Spalten an:\n",
    "* IDx: Index des Token im annotierten Dokument\n",
    "* Token: das Wort wie es im Text vorkommt\n",
    "* Lemma: Die Wortgrundform\n",
    "* PoS: Das Tag f√ºr die Wortart\n",
    "* Dependency: Das Dependenz-Label\n",
    "* Dependency_head_idx: Der Token-Index des Kopf-Token\n",
    "* Dependency_head_text: Der Token-Text des Kopf-Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8577237-3f57-4ea6-8b28-0b385ae09208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create final annotation list\n",
    "annotations = []\n",
    "\n",
    "# iterate token\n",
    "for token in doc:\n",
    "    # Extract annotations\n",
    "    annotation = {\n",
    "        \"Idx\": token.i,\n",
    "        \"Token\": token.text,\n",
    "        \"Lemma\": token.lemma_,\n",
    "        \"PoS\": token.pos_,\n",
    "        \"Dependency\": token.dep_,\n",
    "        \"Dependency_head_idx\": token.head.i,\n",
    "        \"Dependency_head_text\": token.head.text\n",
    "    }\n",
    "    annotations.append(annotation)\n",
    "anno_df = pd.DataFrame(annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d15837-940e-42a5-a012-4bb6929eb180",
   "metadata": {},
   "source": [
    "Der Anfang unserer Tabelle sind dann so aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64db5ed-8f7a-4fef-b9aa-aa36816aa47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b13e537-e3b3-4e85-adef-bc3071508ff9",
   "metadata": {},
   "source": [
    "### Dateien schreiben\n",
    "Zum Schreiben der Dateien m√ºssen wir zuerst einen Dateinamen festlegen. \n",
    "Die Annotationstabellen speichern wir als `.csv`-Datei, die Eintr√§ge einer Reihen werden dabei mit Kommata getrennt. \n",
    "F√ºr die Speicherung der spaCy-eigenen Annotationen gibt es keine standadisierte Dateiendung. Um die Abh√§ngigkeit von spaCy explizit zu machen, setzen wir `.spacy` als Dateiendung. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb07287-60c4-4b33-8e10-4af7ca4ecbc9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "<details>\n",
    "  <summary><b>Informationen zum Ausf√ºhren des Notebooks</b></summary>\n",
    "Der Pfad zum Schreiben der Ergebnisse wird hier auf den selben Ordner gesetzt, in dem das Notebook liegt. So wird nicht von einer bestimmten Ordner-Struktur ausgegangen, wie in der Code-Zeile danach. Dort wird davon ausgeganen, dass auf der selben H√∂he des Ordners, in dem das Notebook liegt, ein Ordner `data` existiert, in dem ein Ordner `csv` vorhanden ist. In dem Ordner `csv` wird die Annotation gespeichert. </br></br>\n",
    "‚ö†Ô∏è Die n√§chste Zeile, in der der Pfad noch einmal gesetzt wird, muss √ºbersprungen werden.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90954af4-2137-4715-b967-9c4c0706ae6f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set output path to current directory\n",
    "output_dir = Path(r\"../data/annotations\")\n",
    "if not output_dir.exists():\n",
    "    output_dir.mkdir()\n",
    "\n",
    "# set file name to original name with a different file extension\n",
    "output_path_spacy = output_dir / text_path.with_suffix(\".spacy\").name\n",
    "output_path_table = output_dir / text_path.with_suffix(\".csv\").name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddac84a-5fbe-4304-9023-b4c0e18ab76e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Der Text wird dann unter dem festgelegten Dateinamen gespeichert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cc1fab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the annotation in spaCy-specific format\n",
    "doc.to_disk(output_path_spacy)\n",
    "\n",
    "# save the annotation in table format\n",
    "anno_df.to_csv(output_path_table, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4391b64a-43b4-4c34-bb40-ee268a39b7b2",
   "metadata": {},
   "source": [
    "Zus√§tzlich schreiben wir eine Dokumentationsdatei, in der folgende Informationen zur Annotation gespeichert werden:\n",
    "* die spaCy-Version,\n",
    "* der Modell-Name\n",
    "* die Modell-Version\n",
    "* das Datum\n",
    "\n",
    "Die Daten speichern wir auch in einer Tabelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d06405-e016-4171-ab1e-b1696a34efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_str = datetime.today().replace(second=0, microsecond=0).isoformat()\n",
    "\n",
    "documentation = {\n",
    "    \"spacy_version\":spacy.__version__,\n",
    "    \"model_name\": f\"{nlp.meta['lang']}_{nlp.meta['name']}\",\n",
    "    \"model_version\": nlp.meta[\"version\"],\n",
    "    \"date\": datetime_str\n",
    "}\n",
    "docu_df = pd.DataFrame([documentation])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e47c4-241d-4029-9841-f3ad0eb55407",
   "metadata": {},
   "source": [
    "Die Dokumentationstabelle sieht so aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2560a9cd-0449-4937-b0b5-48a3245a5ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docu_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127ed6ea-d504-40ff-82d9-0896415e4381",
   "metadata": {},
   "source": [
    "Schreiben der Dokumentationstabelle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dab141e-3ec7-4497-af2f-db9b6b2691b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set file path\n",
    "output_documentation_fp = output_dir / f\"{datetime}_spaCy_annotation_documentation.txt\"\n",
    "\n",
    "# save dataframe to file path\n",
    "docu_df.to_csv(output_documentation_fp, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d865508-e103-4639-9d2b-a3d966aa3f67",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Prozess f√ºr die gesamten Korpora ausf√ºhren \n",
    "Um die gesamten Korpora zu annotieren, sollten wir zuerst absch√§tzen, wie lange die Annotation aller Texte dauern w√ºrde, um ggf. die Performanz der Annotation zu optimieren. \n",
    "\n",
    "```{admonition} Dauer der Annotation f√ºr das gesamte Korpus\n",
    ":class: zeitinfo\n",
    "Die Korpora enthalten jeweils 400 Texte. Mit einer L√§nge von √ºber etwa 47.000 W√∂rtern ist *Feldblumen* ein verh√§ltnism√§√üig kurzer Text, weswegen wir durchschnittlich die dreifache Annotationsdauer pro Text annehmen (wir wollen lieber zu viel als zu wenig Zeit f√ºr die Annotation ansetzen). Die Annotation eines einzelnen Texts sollte somit im Schnitt etwa 15 Sekunden dauern. Die Annotation von 800 Texten dauert dementsprechend 12.000 Sekunden, also 200 Minuten ~ 3 Stunden. \n",
    "```\n",
    "\n",
    "Da dies eher lang erscheint, sollte versucht werden, die Performanz zu optimieren. spaCy stellt daf√ºr z.B. einen Methode bereit, die automatisch eine Liste von Dokumenten verarbeitet (`.pipe()`).\n",
    "Da die Annotation einzelner Texte unabh√§ngig voneinander ist, kann die Prozessierung so automatisiert werden, dass mehrere Texte zeitgleich annotiert werden. Je nach Ausstattung des Computers, der zur Annotation genutzt wird (v.a. die Anzahl von Prozessoren und die Gr√∂√üe des RAM-Speichers sind ausschlaggebend), k√∂nnen unterschiedlich viele Texte zeitgleich prozessiert werden. \n",
    "\n",
    "Die optimierte Annotation wurde auf ein Skript ausgelagert, das sich in dem GitHub-Repositorium der Fallstudie befindet. Das Skript haben wir auf einem MacBook M4 Max mit 13 Kernen und 36GB RAM ausgef√ºhrt. Es ist f√ºr ca. 20 Minuten gelaufen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
